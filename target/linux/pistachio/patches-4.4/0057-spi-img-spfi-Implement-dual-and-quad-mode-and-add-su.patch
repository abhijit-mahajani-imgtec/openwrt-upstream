From 063f1b542e6e9c5ed804d0952784e6656312edec Mon Sep 17 00:00:00 2001
From: Ionela Voinescu <ionela.voinescu@imgtec.com>
Date: Mon, 10 Aug 2015 13:48:04 +0100
Subject: spi: img-spfi: Implement dual and quad mode, and add support for them

This includes following changes :-

1. add support for dual and quad mode
For dual and quad modes to work the SPFI controller needs
to have information about command/address/dummy bytes in the
transaction register. This information is not relevant for
single mode, and therefore it can have any value in the
allowed range. Therefore, for any read or write transfers of less
than 8 bytes (cmd = 1 byte, addr up to 7 bytes), SPFI will be
configured, but not enabled (unless it is the last transfer in
the queue). The transfer will be enabled by the subsequent tranfer.
A pending transfer is determined by the content of the transaction
register: if command part is set and tsize is not.
This way we ensure that for dual and quad transactions
the command request size will apear in the command/address part
of the transaction register, while the data size will be in
tsize, all data being sent/received in the same transaction (as
set up in the transaction register).

Test:
ECC corrections: 0
ECC failures   : 0
Bad blocks     : 4
BBT blocks     : 0
Bad block at 0x08200000
Bad block at 0x18000000
Bad block at 0x18040000
Bad block at 0x1ff00000
Bad block at 0x1ff40000
Bad block at 0x1ff80000
Bad block at 0x1ffc0000

Finished pass 1 successfully
real    8m 32.90s
user    2m 31.40s
sys     1m 53.83s

2. mtd: spi-nand: Implement dual-mode
Read cache operations will from this moment on be performed
in dual mode (bus width = 2).
There is no dual mode operation for programming the cache.

Test:
ECC corrections: 0
ECC failures   : 0
Bad blocks     : 4
BBT blocks     : 0
Bad block at 0x08200000
Bad block at 0x18000000
Bad block at 0x18040000
Bad block at 0x1ff00000
Bad block at 0x1ff40000
Bad block at 0x1ff80000
Bad block at 0x1ffc0000

Finished pass 1 successfully
real    7m 45.10s
user    2m 31.91s
sys     1m 54.66s

3. mtd: spi-nand: Implement quad-mode
Read cache operations will from this moment on be performed
in quad mode (bus width = 4).

Test:

ECC corrections: 0
ECC failures   : 0
Bad blocks     : 4
BBT blocks     : 0
Bad block at 0x08200000
Bad block at 0x18000000
Bad block at 0x18040000
Bad block at 0x1ff00000
Bad block at 0x1ff40000
Bad block at 0x1ff80000
Bad block at 0x1ffc0000

Finished pass 1 successfully
real    7m 41.94s
user    2m 24.96s
sys     2m 4.58s

Change-Id: I0cc1f639312dfb8fdcdf9ba79abc3d7e32e6f66d
Signed-off-by: Ionela Voinescu <ionela.voinescu@imgtec.com>
Signed-off-by: Ezequiel Garcia <ezequiel.garcia@imgtec.com>
---
 drivers/mtd/spi-nand/spi-nand-base.c   | 27 ++++++++++
 drivers/mtd/spi-nand/spi-nand-device.c | 10 ++--
 drivers/spi/spi-img-spfi.c             | 92 +++++++++++++++++++++++++++++-----
 3 files changed, 114 insertions(+), 15 deletions(-)

diff --git a/drivers/mtd/spi-nand/spi-nand-base.c b/drivers/mtd/spi-nand/spi-nand-base.c
index 3012645..2ac76a5 100644
--- a/drivers/mtd/spi-nand/spi-nand-base.c
+++ b/drivers/mtd/spi-nand/spi-nand-base.c
@@ -31,6 +31,7 @@
 
 #define SPI_NAND_FEATURE_REG		0xb0
 #define SPI_NAND_ECC_EN			BIT(4)
+#define SPI_NAND_QUAD_EN		BIT(0)
 
 #define SPI_NAND_STATUS_REG		0xc0
 #define SPI_NAND_STATUS_REG_ECC_MASK	0x3
@@ -83,6 +84,21 @@ static int spi_nand_disable_ecc(struct spi_nand *snand)
 	return 0;
 }
 
+static int spi_nand_enable_quad(struct spi_nand *snand)
+{
+	int ret;
+
+	ret = snand->read_reg(snand, SPI_NAND_FEATURE_REG, snand->buf);
+	if (ret)
+		return ret;
+
+	snand->buf[0] |= SPI_NAND_QUAD_EN;
+	ret = snand->write_reg(snand, SPI_NAND_FEATURE_REG, snand->buf);
+	if (ret)
+		return ret;
+
+	return 0;
+}
 /*
  * Wait until the status register busy bit is cleared.
  * Returns a negatie errno on error or time out, and a non-negative status
@@ -264,6 +280,12 @@ static int spi_nand_read_page(struct spi_nand *snand, unsigned int page_addr,
 		}
 	}
 
+	/* Enable quad mode */
+	ret = spi_nand_enable_quad(snand);
+	if (ret) {
+		dev_err(snand->dev, "error %d enabling quad mode\n", ret);
+		return ret;
+	}
 	/* Get page from the device cache into our internal buffer */
 	ret = snand->read_cache(snand, page_offset, length, snand->data_buf);
 	if (ret < 0) {
@@ -471,6 +493,11 @@ int spi_nand_register(struct spi_nand *snand, struct nand_flash_dev *flash_ids)
 	if (!snand->buf)
 		return -ENOMEM;
 
+	/* This is enabled at device power up but we'd better make sure */
+	ret = spi_nand_enable_ecc(snand);
+	if (ret)
+		return ret;
+
 	/* Preallocate buffer for flash identification (NAND_CMD_READID) */
 	snand->buf_size = SPI_NAND_CMD_BUF_LEN;
 	snand->data_buf = kmalloc(snand->buf_size, GFP_KERNEL);
diff --git a/drivers/mtd/spi-nand/spi-nand-device.c b/drivers/mtd/spi-nand/spi-nand-device.c
index f1639ea..30c83f3 100644
--- a/drivers/mtd/spi-nand/spi-nand-device.c
+++ b/drivers/mtd/spi-nand/spi-nand-device.c
@@ -151,7 +151,7 @@ struct spi_nand_device_cmd {
 	 * so keep them together.
 	 */
 	u32 n_cmd;
-	u8 cmd[4];
+	u8 cmd[5];
 
 	/* Tx data */
 	u32 n_tx;
@@ -160,6 +160,7 @@ struct spi_nand_device_cmd {
 	/* Rx data */
 	u32 n_rx;
 	u8 *rx_buf;
+	u8 rx_nbits;
 };
 
 struct spi_nand_device {
@@ -204,6 +205,7 @@ static int spi_nand_send_command(struct spi_device *spi,
 	if (cmd->n_rx) {
 		x[1].len = cmd->n_rx;
 		x[1].rx_buf = cmd->rx_buf;
+		x[1].rx_nbits = cmd->rx_nbits;
 		spi_message_add_tail(&x[1], &message);
 	}
 
@@ -350,13 +352,15 @@ static int spi_nand_device_read_cache(struct spi_nand *snand,
 	struct spi_nand_device_cmd *cmd = &snand_dev->cmd;
 
 	memset(cmd, 0, sizeof(struct spi_nand_device_cmd));
-	cmd->n_cmd = 4;
-	cmd->cmd[0] = SPI_NAND_READ_CACHE;
+	cmd->n_cmd = 5;
+	cmd->cmd[0] = SPI_NAND_READ_CACHE_X4;
 	cmd->cmd[1] = 0; /* dummy byte */
 	cmd->cmd[2] = (u8)((page_offset & 0xff00) >> 8);
 	cmd->cmd[3] = (u8)(page_offset & 0xff);
+	cmd->cmd[4] = 0; /* dummy byte */
 	cmd->n_rx = length;
 	cmd->rx_buf = read_buf;
+	cmd->rx_nbits = 4;
 
 	dev_dbg(snand->dev, "%s: offset 0x%x\n", __func__, page_offset);
 
diff --git a/drivers/spi/spi-img-spfi.c b/drivers/spi/spi-img-spfi.c
index ba355b9..5dba219 100644
--- a/drivers/spi/spi-img-spfi.c
+++ b/drivers/spi/spi-img-spfi.c
@@ -40,7 +40,7 @@
 #define SPFI_CONTROL_SOFT_RESET			BIT(11)
 #define SPFI_CONTROL_SEND_DMA			BIT(10)
 #define SPFI_CONTROL_GET_DMA			BIT(9)
-#define SPFI_CONTROL_SE			BIT(8)
+#define SPFI_CONTROL_SE				BIT(8)
 #define SPFI_CONTROL_TMODE_SHIFT		5
 #define SPFI_CONTROL_TMODE_MASK			0x7
 #define SPFI_CONTROL_TMODE_SINGLE		0
@@ -51,6 +51,10 @@
 #define SPFI_TRANSACTION			0x18
 #define SPFI_TRANSACTION_TSIZE_SHIFT		16
 #define SPFI_TRANSACTION_TSIZE_MASK		0xffff
+#define SPFI_TRANSACTION_CMD_SHIFT		13
+#define SPFI_TRANSACTION_CMD_MASK		0x1
+#define SPFI_TRANSACTION_ADDR_SHIFT		10
+#define SPFI_TRANSACTION_ADDR_MASK		0x7
 
 #define SPFI_PORT_STATE				0x1c
 #define SPFI_PORT_STATE_DEV_SEL_SHIFT		20
@@ -87,6 +91,7 @@
  */
 #define SPFI_32BIT_FIFO_SIZE			64
 #define SPFI_8BIT_FIFO_SIZE			16
+#define SPFI_DATA_REQUEST_MAX_SIZE		8
 
 struct img_spfi {
 	struct device *dev;
@@ -103,6 +108,8 @@ struct img_spfi {
 	struct dma_chan *tx_ch;
 	bool tx_dma_busy;
 	bool rx_dma_busy;
+
+	bool complete;
 };
 
 struct img_spfi_device_data {
@@ -123,9 +130,11 @@ static inline void spfi_start(struct img_spfi *spfi)
 {
 	u32 val;
 
-	val = spfi_readl(spfi, SPFI_CONTROL);
-	val |= SPFI_CONTROL_SPFI_EN;
-	spfi_writel(spfi, val, SPFI_CONTROL);
+	if (spfi->complete) {
+		val = spfi_readl(spfi, SPFI_CONTROL);
+		val |= SPFI_CONTROL_SPFI_EN;
+		spfi_writel(spfi, val, SPFI_CONTROL);
+	}
 }
 
 static inline void spfi_reset(struct img_spfi *spfi)
@@ -138,12 +147,21 @@ static int spfi_wait_all_done(struct img_spfi *spfi)
 {
 	unsigned long timeout = jiffies + msecs_to_jiffies(50);
 
+	if (!(spfi->complete))
+		return 0;
+
 	while (time_before(jiffies, timeout)) {
 		u32 status = spfi_readl(spfi, SPFI_INTERRUPT_STATUS);
 
 		if (status & SPFI_INTERRUPT_ALLDONETRIG) {
 			spfi_writel(spfi, SPFI_INTERRUPT_ALLDONETRIG,
 				    SPFI_INTERRUPT_CLEAR);
+			/*
+			 * Disable SPFI for it not to interfere with
+			 * pending transactions
+			 */
+			spfi_writel(spfi, spfi_readl(spfi, SPFI_CONTROL)
+			& ~SPFI_CONTROL_SPFI_EN, SPFI_CONTROL);
 			return 0;
 		}
 		cpu_relax();
@@ -494,12 +512,32 @@ static void img_spfi_config(struct spi_master *master, struct spi_device *spi,
 			    struct spi_transfer *xfer)
 {
 	struct img_spfi *spfi = spi_master_get_devdata(spi->master);
-	u32 val, div;
+	u32 val, div, transact;
+	bool is_pending;
 
-	/* Start the transaction from a known (reset) state */
-	spfi_reset(spfi);
+	/*
+	 * For read or write transfers of less than 8 bytes (cmd = 1 byte,
+	 * addr up to 7 bytes), SPFI will be configured, but not enabled
+	 * (unless it is the last transfer in the queue).The transfer will
+	 * be enabled by the subsequent transfer.
+	 * A pending transfer is determined by the content of the
+	 * transaction register: if command part is set and tsize
+	 * is not
+	 */
+	transact = spfi_readl(spfi, SPFI_TRANSACTION);
+	is_pending = ((transact >> SPFI_TRANSACTION_CMD_SHIFT) &
+			SPFI_TRANSACTION_CMD_MASK) &&
+			(!((transact >> SPFI_TRANSACTION_TSIZE_SHIFT) &
+			SPFI_TRANSACTION_TSIZE_MASK));
+
+	/* If there are no pending transactions it's OK to soft reset */
+	if (!is_pending) {
+		/* Start the transaction from a known (reset) state */
+		spfi_reset(spfi);
+	}
 
 	/*
+	 * Before anything else, set up parameters.
 	 * output = spfi_clk * (BITCLK / 512), where BITCLK must be a
 	 * power of 2 up to 128
 	 */
@@ -512,20 +550,50 @@ static void img_spfi_config(struct spi_master *master, struct spi_device *spi,
 	val |= div << SPFI_DEVICE_PARAMETER_BITCLK_SHIFT;
 	spfi_writel(spfi, val, SPFI_DEVICE_PARAMETER(spi->chip_select));
 
-	spfi_writel(spfi, xfer->len << SPFI_TRANSACTION_TSIZE_SHIFT,
-		    SPFI_TRANSACTION);
+	if (!list_is_last(&xfer->transfer_list, &master->cur_msg->transfers) &&
+		(xfer->tx_buf) && (xfer->len <= SPFI_DATA_REQUEST_MAX_SIZE)
+		&& !is_pending) {
+		transact = (1 & SPFI_TRANSACTION_CMD_MASK) <<
+			SPFI_TRANSACTION_CMD_SHIFT;
+		transact |= ((xfer->len - 1) & SPFI_TRANSACTION_ADDR_MASK) <<
+			SPFI_TRANSACTION_ADDR_SHIFT;
+		spfi->complete = false;
+	} else {
+		spfi->complete = true;
+		if (is_pending) {
+			if (xfer->tx_buf) {
+				/* Finish pending transfer first for transmit */
+				spfi_start(spfi);
+				spfi_wait_all_done(spfi);
+				spfi_writel(spfi, spfi_readl(spfi, SPFI_CONTROL) &
+				~SPFI_CONTROL_SPFI_EN, SPFI_CONTROL);
+				transact = 0;
+			}
+			/* Keep setup from pending transfer */
+			transact |= ((xfer->len & SPFI_TRANSACTION_TSIZE_MASK) <<
+				SPFI_TRANSACTION_TSIZE_SHIFT);
+		} else {
+			transact = ((xfer->len & SPFI_TRANSACTION_TSIZE_MASK) <<
+				SPFI_TRANSACTION_TSIZE_SHIFT);
+		}
+	}
+	spfi_writel(spfi, transact, SPFI_TRANSACTION);
 
 	val = spfi_readl(spfi, SPFI_CONTROL);
 	val &= ~(SPFI_CONTROL_SEND_DMA | SPFI_CONTROL_GET_DMA);
-	if (xfer->tx_buf)
+	/*
+	 * We set up send DMA for pending transfers also, as
+	 * those are always send transfers
+	 */
+	if ((xfer->tx_buf) || is_pending)
 		val |= SPFI_CONTROL_SEND_DMA;
 	if (xfer->rx_buf)
 		val |= SPFI_CONTROL_GET_DMA;
 	val &= ~(SPFI_CONTROL_TMODE_MASK << SPFI_CONTROL_TMODE_SHIFT);
-	if (xfer->tx_nbits == SPI_NBITS_DUAL &&
+	if (xfer->tx_nbits == SPI_NBITS_DUAL ||
 	    xfer->rx_nbits == SPI_NBITS_DUAL)
 		val |= SPFI_CONTROL_TMODE_DUAL << SPFI_CONTROL_TMODE_SHIFT;
-	else if (xfer->tx_nbits == SPI_NBITS_QUAD &&
+	else if (xfer->tx_nbits == SPI_NBITS_QUAD ||
 		 xfer->rx_nbits == SPI_NBITS_QUAD)
 		val |= SPFI_CONTROL_TMODE_QUAD << SPFI_CONTROL_TMODE_SHIFT;
 	val |= SPFI_CONTROL_SE;
-- 
2.6.2

